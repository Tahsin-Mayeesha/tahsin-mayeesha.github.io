<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name=viewport content=‚Äúwidth=800‚Äù>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    position: relative;
    }
    .two
    {
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  
<!--
  width: 0;
  height: 0;
-->

  <title>Tahsin Mayeesha</title>
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="my_icon.png">
  </head>

  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="67%" valign="middle">
        <p align="center">
          <name>Tahsin Mayeesha</name>
        </p>
        <!--
	Comment..
        -->
        <p>Hi! üòä I'm working as a researcher focused on NLP, HCI and AI policymaking üåç ‚öñÔ∏è üïäÔ∏è üßë‚Äç‚öñÔ∏è. Currently, I am diving into exciting new challenges at EBLICT-Dream71 joint project of VPA (Virtual Private Assistant), 
	funded by the Bangladesh government where we build Llama based RAG models for making public administration related information accessible to citizens.</p>
		
	<p></p>Prior to this role, I worked as a HCI researcher for a year in <a href="https://sites.google.com/view/nsuhci/home">Design,Inclusion & Access Lab</a>(DIAL) in North South University
	 with my superviser <a href="https://scholar.google.com/citations?user=rXMM2MwAAAAJ&hl=en">Dr. Nova Ahmed</a> in multiple projects in education and AI policy-making. The key projects
	are 1)"My Freedom in Light", where we investigated challenges of women in computing with fictional inquiry and co-design workshop faciliating participatory design from female students
	in computer science, and 2) "Designing Accountable and Ethical AI for the Next Billions: Considering the Needs of South Asian Marginalized Communities" - where we studied current
	state of AI ethics related policies and perspectives with a focus on South Asia and Bangladesh . Publications from these projects have been accepted to ICTD 2024, ACM Compass 2024 and
	Ubicomp 2024. </p>
		  
	<p> Simultaneously, I worked on NLP research as a senior research assistant with supervision of <a href="https://scholar.google.ca/citations?user=L9S6rlUAAAAJ&hl=en">Dr. M. Rashedur Rahman </a> 
	in the project "Bengali NLP : Application in Literature and Natural Language Generation" on multiple topics including answer-aware question generation from passages, and generating
	questions with/without guidance from images. I also finished a predoctoral fellowship in <a href="https://www.fatimafellowship.com/"> Fatima Fellowship</a> on a NLP project with mentor <a href="https://benjamin-mlr.github.io/">Benjamin Muller</a>
        on investigating cultural biases like formality in multilingual generative models. Publications from these projects were accepted to journals and NLP Conferences (EMNLP 2023, MM-NLG Workshop held with INLG 2023). 
        </p>
        <p>
          I've graduated from Computer Science and Engineering (North South University) in 2020. My thesis project was on building deep learning models for question answering systems 
          in Bengali where I trained multilingual BERT models on synthetic data. During my undergrad I worked with <a href="https://www.tensorflow.org/hub">Tensorflow Hub</a> team for Google Summer of Code 2019 with mentor <a href="https://www.linkedin.com/in/vojtech-bardiovsk%C3%BD-05a98581/">Vojtech Bardiovsk√Ω</a>, 
          <a href="https://cyber.harvard.edu/">Berkman Klein Center of Internet and Society</a> with mentor <a href="https://cyber.harvard.edu/people/hroberts">Hal Roberts</a> for Google 
          Summer of Code 2018 and <a href="https://www.linkedin.com/company/cramstack">Cramstack</a> in 2017.
        </p>
        <p>
        When I am not immersed in research, I enjoy watching anime, reading manga or books, and taking care of my cats.üêà‚Äç‚¨õ
        </p>

        <p align=center>
          <a href="mailto:tasmiah.tahsin@northsouth.edu">Email</a> &nbsp/&nbsp
          <!-- 
            add cv link in between href "" 

            Link: 
           
          <a href="">CV</a> &nbsp/&nbsp
           -->
          <a href="https://www.linkedin.com/in/tahsin-mayeesha/"> LinkedIn </a> &nbsp/&nbsp
          <a href="https://scholar.google.com/citations?user=MRDAGP8AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
          <a href="https://github.com/Tahsin-Mayeesha">GitHub</a> &nbsp/&nbsp
          <a href="https://twitter.com/tahsin_mayeesha"> Twitter</a>
        </p>
        </td>
        <td style="padding:0;width:50%;max-width:50%">
        <a href="mayeesha_circle.png"><img style="width:100%;max-width:100%" alt="profile photo" src="mayeesha_circle.png"></a>
        </td>
      </tr>
      </table>

      <hr>

    <!-- 
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>News</heading>
          <p>
            <ul>
              <li>17/12/2020: One Paper is Accepted at Tissue and Cell.</li>
              <li>21/07/2020: One Paper is Accepted at PRIME MICCAI 2020.  </li>
            </ul>
          </p>
        </td>
      </tr>
    </tbody></table>
    -->

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Publications/Preprint</heading>
          <p>
            See also my Google Scholar profile for the <a href="https://scholar.google.com/citations?hl=en&user=MRDAGP8AAAAJ&view_op=list_works&sortby=pubdate"> most recent publications</a> as well 
            as the <a href="https://scholar.google.com/citations?hl=en&user=MRDAGP8AAAAJ&view_op=list_works">most-cited papers</a>.
          </p>
        </td>
      </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='ai_ethics2.png'></div>
            <img src='ai_ethics2.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://ictd.org/">
          <papertitle>AI4Bangladesh: AI Ethics for Bangladesh - Challenges, Risks,Principles, and Suggestions</papertitle></a><br>
          Authors : <strong>Tasmiah Tahsin Mayeesha </strong>, Farzana Islam & Nova Ahmed<br> 
          <em>In The 13th International Conference on Information & Communication Technologies and Development (ICTD 2024), December 09‚Äì11, 2024, Nairobi, Kenya.ACM, New York, NY, USA, 13 pages. https://doi.org/10.1145/3700794.3700820</em><br>
          <!--<font color="red">(Oral Presentation)</font></a> -->
          </p>
          <a href="https://ictd.org/">Paper</a> 

            <p>
              In recent times, the term AI ethics caught the attention among the academics, legislators, developers, and among AI users to promote
          ethical AI development. While countries in the North have led the way in discussions about the direction of ethical and responsible
artificial intelligence development and deployment, perspectives from developing countries like Bangladesh are underrepresented.
Based on 32 qualitative interviews with different stakeholders, including machine learning practitioners, academic researchers, and
policymakers in the emerging AI ecosystem in Bangladesh, this work closely examines the ongoing challenges and opportunities to
ensure AI ethics in Bangladesh with emerging AI usage. In Bangladesh, the government has not yet fully implemented measures to 
empower citizens with AI-related skills, policies, resources, and data ethics, and a significant portion of the population lacks knowledge
in AI. In this paper, we are presenting the findings of AI4Bangladesh project that intend to create the roadmap for ethical AI in
Bangladesh. We outline the core challenges, present situation, and risks of AI for Bangladesh; propose seven AI ethics principles, and
offer suggestions to ensure a transparent, accountable, and fair AI ecosystem for Bangladesh.
            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>

    
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='ubicomp24.png'></div>
            <img src='ubicomp24.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://dl.acm.org/doi/abs/10.1145/3675094.3679002">
          <papertitle> Know Your Users: Towards Explainable AI in Bangladesh </papertitle></a><br>
          Authors : Farzana Islam, <strong>Tasmiah Tahsin Mayeesha</strong> & Nova Ahmed <br> 
          <em>In Companion of the 2024 on ACM International Joint Conference on Pervasive and Ubiquitous Computing (UbiComp '24). Association for Computing Machinery, New York, NY, USA, 890‚Äì893. https://doi.org/10.1145/3675094.3679002</em><br>
          <!--<font color="red">(Oral Presentation)</font></a> -->
          </p>
          <a href="https://dl.acm.org/doi/abs/10.1145/3675094.3679002">Paper</a> 

            <p>
            When we are talking about explainable AI and trying to come out of the black box by going beyond algorithmic transparency, we are being ignorant about a big user community.Although XAI research has advanced over time, there hasn't been much study done on the development, evaluation, and application of explainability methodologies in the global south. In this paper, we focus on Bangladesh, which is a part of the South, to understand the AI user community of this region and show how the explainability needs are different for different users and who should XAI focus on. Our work reflects on the unique needs and constraints of the region and recommends potential directions for accessible and human-centered explainability research.We argue that before developing technology and systems, human requirements should be assessed and comprehended.
            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>


	

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='formality.png'></div>
            <img src='formality.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://aclanthology.org/2023.findings-emnlp.175/">
          <papertitle>In What Languages are Generative Language Models the Most Formal? Analyzing Formality Distribution across Languages</papertitle></a><br>
          Authors : Asim Ersoy, Gerson Vizcarra, <strong>Tasmiah Tahsin Mayeesha </strong> & Benjamin Muller<br> 
          <em>In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 2650‚Äì2666, Singapore. Association for Computational Linguistics.</em>Presented in 3rd Multilingual Representation Learning(MRL) Workshop,co-located with EMNLP In Singapore, Dec 7,2023
<br>
          <!--<font color="red">(Oral Presentation)</font></a> -->
          </p>
          <a href="https://aclanthology.org/2023.findings-emnlp.175/">Paper</a> 

            <p>
              Multilingual generative language models (LMs) are increasingly fluent in a large variety of languages. Trained on the concatenation 
              of corpora in multiple languages, they enable powerful transfer from high-resource languages to low-resource ones. However, it is still unknown 
              what cultural biases are induced in the predictions of these models. In this work, we focus on one language property highly influenced by 
              culture: formality. We analyze the formality distributions of XGLM and BLOOM's predictions, two popular generative multilingual language models, in 5 languages. 
              We classify 1,200 generations per language as formal, informal, or incohesive and measure the impact of the prompt formality on the predictions. 
              Overall, we observe a diversity of behaviors across the models and languages. For instance, XGLM generates informal text in Arabic and Bengali when conditioned 
              with informal prompts, much more than BLOOM. In addition, even though both models are highly biased toward the formal style when prompted neutrally, we find that 
              the models generate a significant amount of informal predictions even when prompted with formal text.We release with this work 6,000 annotated samples, 
              paving the way for future work on the formality of generative multilingual LMs.
            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>



      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='vgq3.png'></div>
            <img src='vgq3.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://aclanthology.org/2023.mmnlg-1.2/">
          <papertitle> Visual Question Generation in Bengali </papertitle></a><br>
          Authors : Mahmud Hasan, Labiba Islam, Jannatul Ruma, <strong>Tasmiah Tahsin Mayeesha </strong> & Rashedur Rahman <br> 
          <em> In Proceedings of the Workshop on Multimodal, Multilingual Natural Language Generation and Multilingual WebNLG Challenge (MM-NLG 2023), pages 10‚Äì19, Prague, Czech Republic. Association for Computational Linguistics.</em>, 2023<br>
          <!--<font color="red">(Oral Presentation)</font></a> -->
          </p>
          <a href="https://aclanthology.org/2023.mmnlg-1.2/">Paper</a> 

            <p>
              The task of Visual Question Generation (VQG) is to generate human-like questions relevant to
the given image. As VQG is an emerging research field, existing works tend to focus only on resource-rich language such as English due
to the availability of datasets. In this paper, we propose the first Bengali Visual Question Gen-
eration task and develop a novel transformer-based encoder-decoder architecture that gener-
ates questions in Bengali when given an image. We propose multiple variants of models - (i) image-only: baseline model of generating questions from images without additional infor-
mation, (ii) image-category and image-answer-
category: guided VQG where we condition

the model to generate questions based on the
answer and the category of expected question.
These models are trained and evaluated on the
translated VQAv2.0 dataset. Our quantitative
and qualitative results establish the first state of
the art models for VQG task in Bengali and
demonstrate that our models are capable of
generating grammatically correct and relevant
questions. Our quantitative results show that
our image-cat model achieves a BLUE-1 score
of 33.12 and BLEU-3 score of 7.56 which is
the highest of the other two variants. We also
perform a human evaluation to assess the qual-
ity of the generation tasks. Human evaluation
suggests that image-cat model is capable of
generating goal-driven and attribute-specific
questions and also stays relevant to the cor-
responding image.
            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='bangla_qg.png'></div>
            <img src='bangla_qg.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://www.sciencedirect.com/science/article/pii/S2666307423000311">
          <papertitle>Transformer Based Answer-Aware Bengali Question Generation.</papertitle></a><br>
          Authors : Jannatul Ferdous Ruma,<strong>Tasmiah Tahsin Mayeesha</strong> & Rashedur M. Rahman.<br> 
          <em>International Journal of Cognitive Computing in Engineering, Volume 4, 2023, Pages 314-326, ISSN 2666-3074.</em><br>
          </p>
          <a href="https://huggingface.co/spaces/Tahsin-Mayeesha/Bangla-Question-Generation">Model</a> /<a href="https://www.sciencedirect.com/science/article/pii/S2666307423000311">Paper</a> 


            <p>
              Question generation (QG), the task of generating questions from text or other forms of data, a significant and challenging subject, 
	      has recently attracted more attention in natural language processing (NLP) due to its vast range of business, healthcare, and education applications through creating quizzes, 
         Frequently Asked Questions (FAQs) and documentation. Most QG research has been conducted in languages with abundant resources, such as English. However, due to the dearth 
	of training data in low-resource languages, such as Bengali, thorough research on Bengali question generation has yet to be conducted. In this article, we propose a system for 
	producing varied and pertinent Bengali questions from context passages in natural language in an answer-aware input format using a series of fine-tuned text-to-text transformer (T5) 
	based models. During our studies with various transformer-based encoder-decoder models and various decoding processes, along with delivering 98% grammatically accurate questions, 
	our fine-tuned BanglaT5 model had the highest 35.77 F-score in RougeL and 38.57 BLEU-1 score with beam search. Our automated and human evaluation results show that our answer-aware 
	QG models can create realistic, human-like questions relevant to the context passage and answer. We also release our code, generated questions, dataset, and models to enable broader question generation research for the Bengali-speaking community. 
            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='ethics.png'></div>
            <img src='ethics.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p> <a href="https://dl.acm.org/doi/10.1145/3608113"> 
          <papertitle>Making ethics at home in Global CS Education: Provoking stories from the Souths</papertitle></a><br>
          Authors : Marisol Wong-
          Villacres, Cat Kutay, Shaimaa Lazem, Nova Ahmed, Cristina Abad, Cesar Collazos, Shady Elbas-
          suoni, Farzana Islam, Deepa Singh, <strong>Tasmiah Tahsin Mayeesha</strong>, Martin Mabeifam Ujakpa, Tariq Zaman & Nicola J Bidwell<br> 
          <em>ACM Journal on Computing and Sustainable Societies, 2023, <strong> Best Journal Paper Award.</strong></em><br>
          </p>
         
          <a href="https://dl.acm.org/doi/10.1145/3608113">Paper</a> 
	  <!--
          <a href="https://github.com/hasibzunair/fifa-tryon">Code</a> /
          <a href="https://bmvc2022.mpi-inf.mpg.de/0418_poster.pdf">Poster</a> / 
          <a href="https://bmvc2022.mpi-inf.mpg.de/0418_video.mp4">Video</a> 
          -->    
            <p>
              University courses and curricula on the ethics of computing are increasing, yet there are few studies about how CS programs should
              account for the diverse ways ethical dilemmas and approaches to ethics are situated in cultural, philosophical and governance systems,
              religions and languages. This paper seeks to prompt conversations about CS education that accounts for ethics in the Global Souths. We
              draw on the experiences and insights of 46 university educators and 9 practitioners, in Latin America, South Asia, Africa, the Middle east
              and Australian First Nations. Our modest study sought to inform revisions of the ACM‚Äôs international curricular guidelines for the Society,
              Ethics and Professionalism knowledge area in undergraduate CS programs. Participants‚Äô responses in surveys and interviews illustrate
              difficulties in translating regional and local practices, explicit or implicit values and the changing impacts of technologies, into a singular
              vocabulary about ethics, such as formal ethical Codes of professional conduct. They illustrate opportunities for university teaching, and
              allied learning activities, to link more closely to students‚Äô priorities, actions and experiences in the Global Souths and enrich students‚Äô
              education in the Global North.
            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>



      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='bangla_qa.jpeg'></div>
            <img src='bangla_qa.jpeg'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://www.tandfonline.com/doi/full/10.1080/24751839.2020.1833136">
          <papertitle>Deep learning based question answering system in Bengali</papertitle></a><br>
          Authors : <strong>Tasmiah Tahsin Mayeesha</strong> , Abdullah Md Sarwar, Rashedur M Rahman<br> 
          <em>Journal of Information and Telecommunication, 5:2, 145-178.</em>, 2021<br>
          </p>
          <a href="https://www.tandfonline.com/doi/full/10.1080/24751839.2020.1833136">Paper</a> / 
          <a href="https://zenodo.org/record/4557874">Dataset</a> 

            <p>
              Recent advances in the field of natural language processing has improved state-of-the-art performances on many tasks including question answering for 
              languages like English. Bengali language is ranked seventh and is spoken by about 300 million people all over the world. But due to lack of data and active 
              research on QA similar progress has not been achieved for Bengali. Unlike English, there is no benchmark large scale QA dataset collected for Bengali, no pretrained 
              language model that can be modified for Bengali question answering and no human baseline score for QA has been established either. In this work we use state-of-the-art 
              transformer models to train QA system on a synthetic reading comprehension dataset translated from one of the most popular benchmark datasets in English called SQuAD 2.0.
              We collect a smaller human annotated QA dataset from Bengali Wikipedia with popular topics from Bangladeshi culture for evaluating our models.
              Finally, we compare our models with human children to set up a benchmark score using survey experiments.
            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='protest.png'></div>
            <img src='protest.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://arxiv.org/pdf/1812.11430">
          <papertitle>Applying Text Mining to Protest Stories as Voice against Media Censorship.</papertitle></a><br>
          Authors : <strong>Tasmiah Tahsin Mayeesha</strong>, Zareen Tasneem, Jasmin Jones & Nova Ahmed.<br>
          <em>ACM Conference on Computer-Supported Co-operative Work and Social Computing, Solidarity Across Borders Workshop,</em>, 2018<br>
          </p>
          <a href="https://arxiv.org/pdf/1812.11430">Paper</a> /
            <p>
              Data driven activism attempts to collect,analyze and visualize data to foster social change. However, during media
              censorship it is often impossible to collect such data. Here we demonstrate that data from personal stories can also help us to
              gain insights about protests and activism which can work as a voice for the activists. </a>.</p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>

      

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading>Projects</heading>
          </td>
        </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='robust_speech.png'></div>
            <img src='robust_speech.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://hasibzunair.github.io/resm3dvton/resources/paper.pdf">
          <papertitle>Bengali Automatic Speech Recognition System</papertitle></a><br>
          <em>Speech to text model for Bengali language, Huggingface Robust Speech Event</em>, 2022<br>
          </p>
          <a href="https://huggingface.co/spaces/huggingface/hf-speech-bench">Huggingface Speech Bench</a> / 
          <a href="https://huggingface.co/Tahsin-Mayeesha/wav2vec2-bn-300m">Model</a> 
          <p>
            Finetuned <a href="https://huggingface.co/facebook/wav2vec2-xls-r-300m">Wav2vec2-xls-r</a> model on <a href="https://huggingface.co/datasets/openslr">openslr</a> Bangla Speech dataset of 200k+ samples which was recognized as one of the best performing model for Bangla for 
            Huggingface Robust Speech Sprint.
          </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>



        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr onmouseout="jump_stop()" onmouseover="jump_start()" >
            <td width="25%">
              <div class="one">
                <div class="two" id = 'jump_image'><img src='bngpt2_86.png'></div>
                <img src='bngpt2_86.png'>
              </div>
              <script type="text/javascript">
                function jump_start() {
                  document.getElementById('jump_image').style.opacity = "1";
                }
                function jump_stop() {
                  document.getElementById('jump_image').style.opacity = "0";
                }
                jump_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <p><a href="https://huggingface.co/flax-community/gpt2-bengali"><papertitle>Bengali GPT2 model</papertitle></a><br>
                <em>Part of Huggingface Flax-Jax Event </em>, 2021<br>

              
              </p>
                <a href="https://huggingface.co/flax-community/gpt2-bengali">Model</a> 
                <p>Large OpenAI GPT-2 model was proposed in <a href="https://paperswithcode.com/paper/language-models-are-unsupervised-multitask">Language Models are Unsupervised Multitask Learners</a> paper.
                  Original GPT2 model was a causal (unidirectional) transformer pretrained using language modeling on a very large corpus of ~40 GB of text data. This model has same configuration but has been pretrained on bengali corpus of 
                  <a href="https://huggingface.co/datasets/mc4">mC4(multilingual C4)</a> dataset.Also features another finetuned variation on <a href="https://huggingface.co/khalidsaifullaah/bengali-lyricist-gpt2?">bengali song lyrics.</a>
                </p>
            </td>
          </tr>
        </tbody></table>


        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
          <td width="25%">
            <div class="one">
            <div class="two" id = 'aperture_image'><img src="card_bot.png"></div>
            <img src="card_bot.png">
            </div>
            <script type="text/javascript">
            function aperture_start() {
            document.getElementById('aperture_image').style.opacity = "1";
            }
            function aperture_stop() {
            document.getElementById('aperture_image').style.opacity = "0";
            }
            aperture_stop()
            </script>
          </td>
          <td valign="top" width="75%">
                <papertitle> <a href="https://github.com/Tahsin-Mayeesha/credit-card-recommender-django-app-and-chatbot">Credit Card Recommender System</a></papertitle></a><br>
                <em>Software Engineering Course</em></a>, 2018
                <a href="https://github.com/Tahsin-Mayeesha/credit-card-recommender-django-app-and-chatbot">Code</a>
                <br>
            <p>Developed a similarity based card recommender model using geoloca-
              tion and card specific features with dataset collected from Bangladeshi banks. Used scikit-learn for
              modelling and deployed with Django web app and Google Dialogflow based chatbot.
            </p>
          </td>
        </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
          <td width="25%">
            <div class="one">
            <div class="two" id = 'aperture_image'><img src="bn_nmt.png"></div>
            <img src="bn_nmt.png">
            </div>
            <script type="text/javascript">
            function aperture_start() {
            document.getElementById('aperture_image').style.opacity = "1";
            }
            function aperture_stop() {
            document.getElementById('aperture_image').style.opacity = "0";
            }
            aperture_stop()
            </script>
          </td>
          <td valign="top" width="75%">
                <papertitle> Dobhashi - English Bangla Machine Translation </papertitle></a><br>
                <em>Natural Language Processing Course</em></a>, 2018
                <a href="https://drive.google.com/file/d/1BNcM3NudmEomHzBvmX4ZqLybKe20Nxt2/view">Report</a>
                <br>
            <p>Architected English-Bangla machine translation model based on LSTM and transformer
              and trained on SUPARA Benchmark Bangla-English corpus. Best performing model achieves a
              BLEU score of 46.
            </p>
          </td>
        </tr>
        </tbody></table>  

        

      <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
          <td width="25%">
            <div class="one">
            <div class="two" id = 'aperture_image'><img src='network_dhaka.png'></div>
            <img src='network_dhaka.png'>
            </div>
            <script type="text/javascript">
            function aperture_start() {
            document.getElementById('aperture_image').style.opacity = "1";
            }
            function aperture_stop() {
            document.getElementById('aperture_image').style.opacity = "0";
            }
            aperture_stop()
            </script>
          </td>
          <td valign="top" width="75%">
                <papertitle> <a href="https://github.com/Tahsin-Mayeesha/Dhaka_Tribune-Network-Visualization">News Article Network Visualization on violence against women</a></papertitle></a><br>
                <a href="https://tahsin-mayeesha.github.io/Dhaka_Tribune-Network-Visualization/#"><em>Interactive Network</em></a>
                <br>
            <p>This project explore the media coverage on the articles about harassment or violence against women, including rape and murder related cases. 
              It was done with the help of KolpoKoushol , an initiative by former MIT alumni‚Äôs of Bangladesh to gather people from many fields for learning about interdisciplinary ideas.
              This project has been featured by Fast.ai. See : <a href="http://www.fast.ai/2017/02/27/not-just-silicon-valley/">Deep Learning, Not just for Silicon Valley</a>.
            </p>
          </td>
        </tr>
        </tbody></table>

        <hr>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Blog Posts</heading>
              <br>
              <p><a href="https://tahsin-mayeesha.github.io/tahsin_mayeesha/fastpages/jupyter/2021/08/04/_bangla-fake-news.html">Classifying Bangla Fake News with HuggingFace Transformers and Fastai
              </a></p>
              <p><a href="https://medium.com/learning-machine-learning/gsoc19-with-tensorflow-hub-8e3014369b16">Google Summer of Code 19 with TensorFlow Hub</a></p>
              <p><a href="https://medium.com/learning-machine-learning/building-a-credit-card-recommender-and-deploying-on-web-and-chatbot-platform-91bd7baf2798">Building a Credit Card Recommender </a></p>
              <p><a href="https://medium.com/learning-machine-learning/gsoc-2018-network-visualization-of-mediacloud-topic-network-1st-evaluation-part-2-ca72e25a88d5">Google Summer of Code 2018 : Network Visualization Of MediaCloud Topic Network
              </a></p>  
              <p><a href="https://medium.com/learning-machine-learning/multi-class-fish-classification-from-images-with-transfer-learning-using-keras-335125637544">Multi class Fish Classification on Images using Transfer Learning and Keras</a></p>
              <p><a href="https://medium.com/learning-machine-learning/recommending-animes-using-nearest-neighbors-61320a1a5934">Recommending Animes Using Nearest Neighbors</a></p>
            </td>
          </tr>
        </table>          
      


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Honors/Awards</heading>
              <p></p>
	      <p><i>Best Journal Paper Award, ACM Compass 2023</i></p>
              <p><i>Humayun Ahmed Research Fellowship. NSU HCI DIAL Lab.</i>, 2023</p>
              <p>
                <i>Weights and Bias Fastai x Huggingface study group blog competition winning submission</i>, 2020  <br>
                <a href="https://github.com/Tahsin-Mayeesha/bangla-fake-news">Code</a>
              </p>
              <p><i><a href="https://www.udacity.com/facebook-AI-scholarship">Secure and Private AI Scholarship Challenge, Udacity-Facebook</a></i>, 2019</p>
              <p><i>AWS Machine Learning Scholarship, Udacity-Amazon</i>, 2018</p>
              <p><i>Fast.ai International Fellowship, 2018.</i>
                Featured in Forbes article - <a href="https://www.forbes.com/sites/mariyayao/2017/04/10/why-we-need-to-democratize-ai-machine-learning-education/?sh=b0e31fc1197d">
                Artificial Intelligence Education Transforms The Developing World</a>, <a href="https://www.fast.ai/posts/2017-02-27-not-just-silicon-valley.html">Deep Learning, not just for Silicon Valley
                </a>
              </p>
              <p>
              <i>Udacity Machine Learning Nanodegree, 2017.</i> Capstone project on multi-class image classification on fishery images. <a href="https://github.com/Tahsin-Mayeesha/udacity-mlnd-deeplearning-capstone">Code.</a>
            </td>
          </tr>
        </table>          


        <!--
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Machine Learning Competitions</heading>
              <p></p>
              <p><i>Product Counting and Recognition for Retail Checkout</i>, AI City Challenge, CVPR Workshop, 2022 (<font color="red">3rd Place</font>) <br>
                <a href="https://arxiv.org/abs/2204.11024">Paper</a> / <a href="https://github.com/istiakshihab/automated-retail-checkout-aicity22">Code</a> / <a href="https://github.com/NVIDIAAICITYCHALLENGE/2022AICITY_Code_From_Top_Teams/#track-4-multi-class-product-counting--recognition-for-automated-retail-checkout">Leaderboard</a></p>

                <p><i>Tuberculosis Type Classification</i>, ImageCLEF, 2021 (<font color="red">2nd Place</font>) <br>
                  <a href="https://arxiv.org/abs/2105.12810">Paper</a> / <a href="https://github.com/hasibzunair/viptt-net">Code</a> / <a href="https://www.aicrowd.com/challenges/imageclef-2021-tuberculosis-tbt-classification/leaderboards">Leaderboard</a></p>

                <p><i>Nuclei Segmentation and Classification</i>, MoNuSAC, 2020 (<font color="red">11th Place</font>) <br>
                  <a href="https://www.researchgate.net/profile/Ruchika-Verma-3/publication/352228330_L11_Patch_Efficient_Convolutional_Network_for_Multi-Organ_Nuclei_Segmentation_and_Classification/links/60c011c4a6fdcc512815fac6/L11-Patch-Efficient-Convolutional-Network-for-Multi-Organ-Nuclei-Segmentation-and-Classification.pdf">Paper</a> / <a href="https://github.com/hasibzunair/MoNuSAC-ISBI-2020">Code</a> / <a href="https://monusac-2020.grand-challenge.org/Results/">Leaderboard</a></p>
                
                <p><i>Tuberculosis Prediction</i>, ImageCLEF, 2019 (<font color="red">5th Place</font>) <br>
                  <a href="https://arxiv.org/abs/2007.13224">Paper</a> / <a href="https://github.com/hasibzunair/uniformizing-3D">Code</a> / <a href="https://www.imageclef.org/2019/medical/tuberculosis">Leaderboard</a></p>
                
                <p><i>Bengali Handwritten Digit Recognition</i>, Bengali.AI, 2019 (<font color="red">6th Place</font>) <br>
                  <a href="https://www.researchgate.net/publication/326989744_Unconventional_Wisdom_A_New_Transfer_Learning_Approach_Applied_to_Bengali_Numeral_Classification">Paper</a> / <a href="https://github.com/hasibzunair/unconventional-wisdom">Code</a> / <a href="https://www.kaggle.com/competitions/numta/leaderboard">Leaderboard</a></p>

                </td>
          </tr>
        </table>   
      -->
        <hr>
        
        <!-- 
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Datasets</heading>
              <p></p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
          <td width="25%">
            <div class="one">
              <div class="two" id = 'jump_image'><img src='covid.png'></div>
              <img src='covid.png'>
            </div>
            <script type="text/javascript">
              function jump_start() {
                document.getElementById('jump_image').style.opacity = "1";
              }
              function jump_stop() {
                document.getElementById('jump_image').style.opacity = "0";
              }
              jump_stop()
            </script>
          </td>
          <td valign="top" width="75%">
      <p><a href="https://arxiv.org/abs/2106.09759">
            <papertitle>Synthetic COVID-19 Chest X-ray Dataset for Computer-Aided Diagnosis</papertitle></a><br>
            Authors : <strong>Hasib Zunair</strong> and A. Ben Hamza<br> 
            <em>ICML Workshop on Computational Biology</em>, 2021 <font color="red">(Poster Presentation)</font><br>
            <a href="https://github.com/hasibzunair/synthetic-covid-cxr-dataset">Dataset Link</a>
             
              <p>The dataset consists of 21,295 synthetic COVID-19 chest X-ray images generated using <a href="https://github.com/hasibzunair/synthetic-covid-cxr-gen">algorithm</a>. 
                Dataset is publicly available <a href="https://github.com/hasibzunair/synthetic-covid-cxr-dataset/releases/tag/v0.1">here</a>. The primary use of this dataset
                is to be used as additional data for training machine learning models.
               </p>
              <p></p>
              </a></p>
            </td>
          </tr>
        </table>
        -->

<!-- 
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Teaching</heading>
              <p>
              
              <p>Intro to Deep Learning with PyTorch, 2022</p>
              <p>Building ML models with TensorFlow, Ericsson Canada, 2021</p>
              <p>3D image classification from CT scans, Keras, TensorFlow, 2020</p>
              <p>Intro to Deep Learning for Image Classification using Python, NSU, 2019</p>
              <p> <a href="https://github.com/hasibzunair/whats-image-classifcation-really"></a>Basics of Image Processing and Computer Vision, NSU, 2018</p>
              <p>Intro to Python Programming, NSU, 2018</p>
              </p>
            </td>
          </tr>
          </table>
-->

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading>Mentorship</heading>
            <p><i>Bengali NLP : Application in Literature and Natural Language Generation Project(2023)</i>: Mentoring two graduated research assistants on Bengali Visual Question Generation Research</p>
            <p><i>My Freedom in Light(2023)</i>: Mentoring undergraduate research assistants in report writing and literature review. </p>
          </td>
        </tr>
      </table>

        <hr>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Posters, Invited Talks & Presentations </heading>
              <p></p>
		<a href="https://www.iaseai.org/conference"> <p>Delegate, <i> The Inaugural Conference of the International Association for Safe and Ethical AI </i> Paris, OECD Headquarters </a>, 2024
                <br    
		<a href="https://www.linkedin.com/posts/abiha-zahra-4b157753_itu-admissionsopen-admission2024-activity-7212361971566837761-sw5U/"> <p>Panelist, <i> AI and Social Balance - The current Landscape</i> ITU Punjab, Pakistan </a>, 2024
                <br>		
		<p> Panelist <i>AI - Womens Risks and Opportunities in Banglades</i> Naripokhkho, 2023.</p>
		<p><a href="https://www.youtube.com/watch?v=VK0XyhhB18o"> Goethe-Institut and HerStory Foundation - Presentation on AI Ethics Articles</a>, 2022.</p>
                <p>NLP Reading Group Dhaka- <i>Language Models are Few-Shot Learners</i> Paper Presentation, 2022. </p>
                <a href="https://www.youtube.com/watch?v=unNk7drG6yQ"><p><i>W&B Study Group: fastai w/ Hugging Face Demo Day</i></a>, 2022
                <br>
                <a href="https://www.facebook.com/watch/live/?ref=watch_permalink&v=478515486782906"><p><i>Breaking into research for undergraduate students - Free Schooling Bangladesh</i></a>, 2021
                <br>
                <a href="https://www.youtube.com/live/nZ1QaUFi8rg?feature=share"> <p><i>Udacity School Of Artificial Intelligence Open House</i></a>, 2020
                <br>
            </td>
          </tr>
        </table>   

      <hr>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      </font>
        </p>
        <p align="right">
          <font size="2">
          Template reference - <a href="https://jonbarron.info/">Jon Barron</a?
          </font>
        </p>

    </td>
    </tr>
  </table>
  </body>
</html>
